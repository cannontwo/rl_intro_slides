@book{Bertsekas1996NeurodynamicP,
  title={Neuro-Dynamic Programming},
  author={Dimitri P. Bertsekas and John N. Tsitsiklis},
  booktitle={Optimization and neural computation series},
  year={1996}
}
@inproceedings{Krizhevsky2012ImageNetCW,
  title={ImageNet Classification with Deep Convolutional Neural Networks},
  author={Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  booktitle={NIPS 2012},
  year={2012}
}
@article{Hopcroft1984OnTC,
author = {J.E. Hopcroft and J.T. Schwartz and M. Sharir},
title ={On the Complexity of Motion Planning for Multiple Independent Objects; PSPACE-Hardness of the "Warehouseman's Problem"},
journal = {The International Journal of Robotics Research},
volume = {3},
number = {4},
pages = {76-88},
year = {1984}
}
@article{Henderson2017DeepRL,
  title={Deep Reinforcement Learning That Matters},
  author={Peter Henderson and Riashat Islam and Philip Bachman and Joelle Pineau and Doina Precup and David Meger},
  journal={ArXiv},
  year={2017},
  volume={abs/1709.06560}
}
@inproceedings{Rajeswaran2017TowardsGA,
  title={Towards Generalization and Simplicity in Continuous Control},
  author={Aravind Rajeswaran and Kendall Lowrey and Emanuel Todorov and Sham M. Kakade},
  booktitle={NIPS},
  year={2017}
}
@article{Montfar2014OnTN,
  title={On the Number of Linear Regions of Deep Neural Networks},
  author={Guido Mont{\'u}far and Razvan Pascanu and Kyunghyun Cho and Yoshua Bengio},
  journal={ArXiv},
  year={2014},
  volume={abs/1402.1869}
}
@inproceedings{balestriero2019geometry,
  title={The geometry of deep networks: Power diagram subdivision},
  author={Balestriero, Randall and Cosentino, Romain and Aazhang, Behnaam and Baraniuk, Richard},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15806--15815},
  year={2019}
}
@inproceedings{Alshiekh2017SafeRL,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347}
}
@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}
@book{Sutton1998IntroductionTR,
  title={Introduction to Reinforcement Learning},
  author={Richard S. Sutton and Andrew G. Barto},
  year={1998}
}
@book{Bertsekas1995DynamicPA,
  title={Dynamic Programming and Optimal Control},
  author={Dimitri P. Bertsekas},
  year={1995}
}
@article{Sutton1988LearningTP,
  title={Learning to Predict by the Methods of Temporal Differences},
  author={Richard S. Sutton},
  journal={Machine Learning},
  year={1988},
  volume={3},
  pages={9-44}
}
@book{khalil2002nonlinear,
  title={Nonlinear Systems},
  author={Khalil, Hassan K},
  publisher = "Prentice Hall",
  year={2002}
}
@book{ljung,
  author = "Ljung, Lennart.",
  booktitle = "System Identification : Theory for the User",
  publisher = "Prentice Hall",
  title = "System identification : theory for the user ",
  year = "1999"
}
@article{continuation,
  author = {Henderson, Michael E.},
  title = {MULTIPLE PARAMETER CONTINUATION: COMPUTING IMPLICITLY DEFINED k-MANIFOLDS},
  journal = {International Journal of Bifurcation and Chaos},
  volume = {12},
  number = {03},
  pages = {451-476},
  year = {2002},
}
@book{Trefethen2013,
	Author = {Trefethen, L. N.},
	Publisher = {Philadelphia, PA: Society for Industrial and Applied Mathematics (SIAM)},
	Title = {{Approximation Theory and Approximation Practice}},
	Year = {2013},
}
@book{anderson2007optimal,
  title={Optimal Control: Linear Quadratic Methods},
  author={Anderson, B.D.O. and Moore, J.B.},
  year={2007},
  publisher={Dover Publications}
}
@inproceedings{lillicrap2015continuous,
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle = {International Conference on Learning Representations},
  title = {{Continuous control with deep reinforcement learning}},
  url = {http://arxiv.org/abs/1509.02971},
  year = {2016}
}
@article{brockman2016openai,
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal = {arXiv preprint arXiv:1606.01540},
  title = {{Openai gym}},
  year = {2016}
}
@article{Bellemare2013,
  author = {Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal = {Journal of Artificial Intelligence Research},
  pages = {253--279},
  title = {{The arcade learning environment: An evaluation platform for general agents}},
  volume = {47},
  year = {2013}
}
@article{CATMULL1978350,
  title = "Recursively generated B-spline surfaces on arbitrary topological meshes",
  journal = "Computer-Aided Design",
  volume = "10",
  number = "6",
  pages = "350 - 355",
  year = "1978",
  author = "E. Catmull and J. Clark",
}
@article{kavraki1996probabilistic,
  title={Probabilistic roadmaps for path planning in high-dimensional configuration spaces},
  author={Kavraki, Lydia E and Svestka, Petr and Latombe, J-C and Overmars, Mark H},
  journal={IEEE transactions on Robotics and Automation},
  volume={12},
  number={4},
  pages={566--580},
  year={1996},
  publisher={IEEE}
}
@book{choset2005principles,
  title={Principles of robot motion: theory, algorithms, and implementation},
  author={Choset, Howie M and Hutchinson, Seth and Lynch, Kevin M and Kantor, George and Burgard, Wolfram and Kavraki, Lydia E and Thrun, Sebastian},
  year={2005},
  publisher={MIT Press}
}
@article{mason1986,
  author = {Matthew T. Mason},
  title ={Mechanics and Planning of Manipulator Pushing Operations},
  journal = {The International Journal of Robotics Research},
  volume = {5},
  number = {3},
  pages = {53-71},
  year = {1986},
  doi = {10.1177/027836498600500303}
}
@book{de1997computational,
  title={Computational geometry},
  author={De Berg, Mark and Van Kreveld, Marc and Overmars, Mark and Schwarzkopf, Otfried},
  booktitle={Computational Geometry},
  year={1997},
  publisher={Springer}
}
@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={Springer}
}
@book{brenner2007mathematical,
  title={The mathematical theory of finite element methods},
  author={Brenner, Susanne and Scott, Ridgway},
  volume={15},
  year={2007},
  publisher={Springer}
}
@book{jacobson1970differential,
  title={Differential Dynamic Programming},
  author={Jacobson, D.H. and Mayne, D.Q.},
  year={1970},
  publisher={American Elsevier Publishing Company}
}
@inproceedings{Li2004IterativeLQ,
  title={Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems},
  author={Weiwei Li and Emanuel Todorov},
  booktitle={ICINCO},
  year={2004}
}
@article{JOHANSEN1997159,
  title = "Operating regime based process modeling and identification",
  journal = "Computers \& Chemical Engineering",
  volume = "21",
  number = "2",
  pages = "159 - 176",
  year = "1997",
  author = "Tor A. Johansen and Bjarne A. Foss"
}
@article{Rantzer2000,
  author = {Rantzer, Anders and Johansson, Mikael},
  journal = {IEEE Transactions on Automatic Control},
  number = {4},
  pages = {629--637},
  title = {{Piecewise linear quadratic optimal control}},
  volume = {45},
  year = {2000}
}
@article{Sontag1981,
  author = {D., Sontag E},
  journal = {IEEE Transactions on Automatic Control},
  number = {2},
  pages = {346--358},
  title = {{Nonlinear Regulation: The piece-wise linear approach}},
  volume = {26},
  year = {1981}
}
@article{Levine2015EndtoEndTO,
  title={End-to-End Training of Deep Visuomotor Policies},
  author={Sergey Levine and Chelsea Finn and Trevor Darrell and Pieter Abbeel},
  journal={JMLR},
  year={2015},
  volume={17},
  pages={39:1-39:40}
}
@book{puterman2014markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={2005},
  publisher={John Wiley \& Sons}
}
@TECHREPORT{Rummery94on-lineq-learning,
    author = {G. A. Rummery and M. Niranjan},
    title = {On-Line Q-Learning Using Connectionist Systems},
    institution = {Cambridge University},
    year = {1994}
}
@article{Paden2016ASO,
  title={A Survey of Motion Planning and Control Techniques for Self-Driving Urban Vehicles},
  author={Brian Paden and Michal C{\'a}p and Sze Zheng Yong and Dmitry S. Yershov and Emilio Frazzoli},
  journal={IEEE Transactions on Intelligent Vehicles},
  year={2016},
  volume={1},
  pages={33-55}
}
@article{Recht2019,
  author = {Recht, Benjamin},
  title = {A Tour of Reinforcement Learning: The View from Continuous Control},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {2},
  number = {1},
  pages = {253-279},
  year = {2019},
}
@article{Ma2018FrictionVI,
  title={Friction Variability in Planar Pushing Data: Anisotropic Friction and Data-Collection Bias},
  author={Daolin Ma and Alberto Rodriguez},
  journal={IEEE Robotics and Automation Letters},
  year={2018},
  volume={3},
  pages={3232-3239}
}
@inproceedings{Benallegue2017RobotMP,
  title={Robot Motion Planning and Control: Is It More than a Technological Problem?},
  author={Mehdi Benallegue and Jean-Paul Laumond and Nicolas Mansard},
  booktitle={Geometric and Numberical Foundations of Movements},
  publisher={Springer},
  series={Springer Tracts in Advanced Robotics},
  volume=117,
  pages={1-10},
  year={2017}
}
@book{anderson2005optimal,
  title={Optimal filtering},
  author={Anderson, Brian DO and Moore, John B},
  year={2005},
  publisher={Dover}
}
@misc{openai2019solving,
    title={Solving Rubik's Cube with a Robot Hand},
    author={OpenAI and Ilge Akkaya and Marcin Andrychowicz and Maciek Chociej and Mateusz Litwin and Bob McGrew and Arthur Petron and Alex Paino and Matthias Plappert and Glenn Powell and Raphael Ribas and Jonas Schneider and Nikolas Tezak and Jerry Tworek and Peter Welinder and Lilian Weng and Qiming Yuan and Wojciech Zaremba and Lei Zhang},
    year={2019},
    eprint={1910.07113},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@book{hespanha2018linear,
  title={Linear Systems Theory},
  author={Hespanha, Joao P},
  year={2018},
  publisher={Princeton University Press}
}
@book{ioannou2012robust,
  title={Robust adaptive control},
  author={Ioannou, Petros A and Sun, Jing},
  year={2012},
  publisher={Courier Corporation}
}
@article{feng2002stability,
  title={Stability analysis of piecewise discrete-time linear systems},
  author={Feng, Gang},
  journal={IEEE Transactions on Automatic Control},
  volume={47},
  number={7},
  pages={1108--1112},
  year={2002},
  publisher={IEEE}
}
@article{perkins2002lyapunov,
  title={Lyapunov design for safe reinforcement learning},
  author={Perkins, Theodore J and Barto, Andrew G},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Dec},
  pages={803--832},
  year={2002}
}
@ARTICLE{Bemporad, 
  author={A. {Bemporad} and A. {Garulli} and S. {Paoletti} and A. {Vicino}}, 
  journal={IEEE Transactions on Automatic Control}, 
  title={A bounded-error approach to piecewise affine system identification},
  year={2005}, 
  volume={50}, 
  number={10}, 
  pages={1567-1580}
} 
@article{Mania2019,
abstract = {We study the performance of the certainty equivalent controller on Linear Quadratic (LQ) control problems with unknown transition dynamics. We show that for both the fully and partially observed settings, the sub-optimality gap between the cost incurred by playing the certainty equivalent controller on the true system and the cost incurred by using the optimal LQ controller enjoys a fast statistical rate, scaling as the square of the parameter error. To the best of our knowledge, our result is the first sub-optimality guarantee in the partially observed Linear Quadratic Gaussian (LQG) setting. Furthermore, in the fully observed Linear Quadratic Regulator (LQR), our result improves upon recent work by Dean et al. (2017), who present an algorithm achieving a sub-optimality gap linear in the parameter error. A key part of our analysis relies on perturbation bounds for discrete Riccati equations. We provide two new perturbation bounds, one that expands on an existing result from Konstantinov et al. (1993), and another based on a new elementary proof strategy.},
annote = {Interesting finit-time analysis of CE{\$} control of LQR systems suggesting that online estimation is reasonable. Also includes a novel Ricatti solution perturbation bound},
archivePrefix = {arXiv},
arxivId = {1902.07826},
author = {Mania, Horia and Tu, Stephen and Recht, Benjamin},
eprint = {1902.07826},
file = {:home/cannon/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mania, Tu, Recht - 2019 - Certainty Equivalence is Efficient for Linear Quadratic Control.pdf:pdf},
mendeley-groups = {Machine Learning/Reinforcement Learning},
number = {NeurIPS},
title = {{Certainty Equivalence is Efficient for Linear Quadratic Control}},
url = {http://arxiv.org/abs/1902.07826},
year = {2019}
}
@article{dean2019sample,
  title={On the sample complexity of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  journal={Foundations of Computational Mathematics},
  pages={1--47},
  year={2019},
  publisher={Springer}
}
@article{Deisenroth2011,
abstract = {In this paper, we introduce PILCO, a practical, data-efficient model-based$\backslash$npolicy search method. PILCO reduces model bias, one of the key problems$\backslash$nof model-based reinforcement learning, in a principled way. By learning$\backslash$na probabilistic dynamics model and explicitly incorporating model$\backslash$nuncertainty into long-term planning, PILCO can cope with very little$\backslash$ndata and facilitates learning from scratch in only a few trials.$\backslash$nPolicy evaluation is performed in closed form using state-of-the-art$\backslash$napproximate inference. Furthermore, policy gradients are computed$\backslash$nanalytically for policy improvement. We report unprecedented learning$\backslash$nefficiency on challenging and high-dimensional control tasks.},
annote = {Not very well-written, but impressive and sample-efficient for realistic control tasks. Uses a Gaussian Process to model dynamics and analytic policy gradients to do policy search. This could be a good paper to connect my PhD idea to -- maybe make the connection between learning parameters (means, scales, weights) for an exponential kernel and moving around voronoi regions?},
author = {Deisenroth, Marc P and Rasmussen, Carl E},
file = {:home/cannon/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Rasmussen - 2011 - P{\{}ILCO A Model-Based and Data-Efficient Approach to Policy Search{\}}.pdf:pdf},
isbn = {978-1-4503-0619-5},
journal = {Proceedings of the International Conference on Machine Learning},
mendeley-groups = {PhD Investigation - Fall 2018,Machine Learning/Reinforcement Learning/Robotic RL,Machine Learning/Reinforcement Learning,Machine Learning/Reinforcement Learning/Model-Based RL},
pages = {465--472},
title = {{P{\{}ILCO: A Model-Based and Data-Efficient Approach to Policy Search{\}}}},
year = {2011}
}
@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}
@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}
@inproceedings{Randlv1998LearningTD,
  title={Learning to Drive a Bicycle Using Reinforcement Learning and Shaping},
  author={J. Randl{\o}v and P. Alstr{\o}m},
  booktitle={ICML},
  year={1998}
}
@inproceedings{Ng2003AutonomousHF,
  title={Autonomous Helicopter Flight via Reinforcement Learning},
  author={A. Ng and H. Kim and Michael I. Jordan and S. Sastry},
  booktitle={NIPS},
  year={2003}
}
@article{Mnih2013PlayingAW,
  title={Playing Atari with Deep Reinforcement Learning},
  author={V. Mnih and K. Kavukcuoglu and D. Silver and A. Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  journal={ArXiv},
  year={2013},
  volume={abs/1312.5602}
}
